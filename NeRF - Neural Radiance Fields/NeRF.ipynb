{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import reshape\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_file_path):\n",
    "\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(data_dict, base_img_dir = 'Data/ship/'):\n",
    "    '''\n",
    "        Implement the function to get the image path and corresponding camera transformation matrix.\n",
    "    '''\n",
    "\n",
    "    img_paths = []\n",
    "    img_cam_transform_matrices = []\n",
    "\n",
    "    all_frames = data_dict[\"frames\"]\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class getImage():\n",
    "\tdef __init__(self, imageWidth, imageHeight):\n",
    "\n",
    "\t\tself.imageWidth = imageWidth\n",
    "\t\tself.imageHeight = imageHeight\n",
    "\n",
    "\tdef __call__(self, imagePath):\n",
    "\n",
    "\t\timage = read_file(imagePath)\n",
    "\t\timage = decode_jpeg(image, 3)\n",
    "\t\timage = convert_image_dtype(image, dtype=tf.float32)\n",
    "\t\timage = resize(image, (self.imageWidth, self.imageHeight))\n",
    "\t\timage = reshape(image, (self.imageWidth, self.imageHeight, 3))\n",
    "\n",
    "\t\treturn image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rays_for_image_matrix(width, height, camera2world_matrix, focal_length):\n",
    "\n",
    "    r_mat = camera2world_matrix[:3, :3]\n",
    "    o_vec = camera2world_matrix[:3, -1:]\n",
    "\n",
    "    i, j =  np.meshgrid(\n",
    "            np.arange(height, dtype=np.float32),\n",
    "            np.arange(width, dtype=np.float32),\n",
    "                        indexing='ij')\n",
    "\n",
    "    vector_x = j - width*0.5\n",
    "    vector_y = - (i - height*0.5)\n",
    "    vector_z = - np.ones_like(vector_x)*focal_length\n",
    "\n",
    "    dirs = np.stack((vector_x, vector_y, vector_z), axis=2)\n",
    "    ray_dirs = np.sum(r_mat * dirs[:, :, None, :], axis=3)\n",
    "\n",
    "    origins = np.ones_like(ray_dirs)*o_vec.squeeze()\n",
    "\n",
    "    return ray_dirs, origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampled_ray_points(ray_dirs, near=1, far=10, num_samples=20):\n",
    "\n",
    "    bins = np.linspace(near, far, num_samples)\n",
    "    ran_samples = np.random.uniform(size=(list(ray_dirs.shape[:-1])+[num_samples]))  # generate random samples for each point of the input matrix\n",
    "    scaled_ran_samples = ran_samples*(far-near)/num_samples\n",
    "    ray_samples = scaled_ran_samples + np.broadcast_to(bins, shape=(list(ray_dirs.shape[:-1])+[num_samples]))\n",
    "\n",
    "    return ray_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, concatenate\n",
    "\n",
    "\n",
    "class NeRFModel(Model):\n",
    "\n",
    "    def __init__(self, positional_encode_size, direction_encode_size, dense_layer_size, batch_size, skip_layer_idx, name=None):\n",
    "        super(NeRFModel, self).__init__(name)\n",
    "\n",
    "        self._skip_idx_val = skip_layer_idx\n",
    "\n",
    "        ### TODO NOTE THE INPUT DIMENSIONS MAY BE WRONG! CHECK AND FIX BEFORE USING THE MODEL  \n",
    "        # Roughly dimension should be (img_height ,img_width, num_of_sample_ray_points, point_encoding_size) per frame\n",
    "        self.__ray_input_layer  = Input(shape=(None, None, None, positional_encode_size), batch_size=batch_size)  #None, None, None, 2 * 3 * positional_encode_size + 3\n",
    "        self.__directional_input_layer = Input(shape=(None, None, None, direction_encode_size), batch_size=batch_size)\n",
    "        \n",
    "        self.__dense_layers = []\n",
    "\n",
    "        for i in range(8):\n",
    "            self.__dense_layers.append(Dense(units=dense_layer_size, activation=\"relu\"))\n",
    "\n",
    "        self.__density_output = Dense(units=1, activation=\"relu\")\n",
    "\n",
    "        self.__inner_feature = Dense(units=dense_layer_size)\n",
    "        self.__inner_dense1 = Dense(units=dense_layer_size//2, activation=\"relu\")\n",
    "        self.__output_dense = Dense(units=3, activation=\"sigmoid\")\n",
    "\n",
    "\n",
    "    def call(self, rays, dirs):\n",
    "\n",
    "        x = self.__ray_input_layer(rays)\n",
    "\n",
    "        for i in range(self.__dense_layers):\n",
    "            \n",
    "            x = self.__dense_layers[i](x)\n",
    "            \n",
    "            # if residual connection point\n",
    "            if i % self._skip_idx_val == 0 and i > 0:\n",
    "                # inject the residual connection\n",
    "                x = concatenate([x, rays], axis=-1)\n",
    "        \n",
    "        # Density value\n",
    "        density_vals = self.__density_output(x)\n",
    "\n",
    "        # Color value\n",
    "        color_features = self.__inner_feature(x)\n",
    "        x = concatenate([color_features, dirs], axis=-1)\n",
    "        x = self.__inner_dense1(x)\n",
    "        color_vals = self.__output_dense(x)\n",
    "        \n",
    "        return color_vals, density_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the provided implementation of the original source code repo, since it is bit different from what I understood from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_image_depth(colors, volume_density, sample_values):\n",
    "\n",
    "\t# calculate the delta between adjacent samples\n",
    "\tdelta = sample_values[..., 1:] - sample_values[..., :-1]\n",
    "\tdelta = tf.concat([delta, [1e10]], axis=-1)\n",
    "\n",
    "\t# calculate alpha from sigma and delta values\n",
    "\talpha = 1.0 - tf.exp(-volume_density * delta)\n",
    "\n",
    "    # calculate the transmittance and weights of the ray points\n",
    "\texpTerm = tf.exp(-volume_density * delta)\n",
    "\tepsilon = 1e-10\n",
    "\ttransmittance = tf.math.cumprod(expTerm + epsilon, axis=-1, exclusive=True)\n",
    "\tweights = alpha * transmittance\n",
    "\t\n",
    "\t# build the image and depth map from the points of the rays\n",
    "\timage = tf.reduce_sum(weights[..., None] * colors, axis=-2)\n",
    "\tdepth = tf.reduce_sum(weights * sample_values, axis=-1)\n",
    "\t\n",
    "\t# return rgb, depth map and weights\n",
    "\treturn (image, depth, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_fine_samples(weights, bins, size):\n",
    "\n",
    "    cum_weights = np.sum(weights)\n",
    "    pdf = weights/cum_weights\n",
    "    cdf = np.concatenate(([0], np.cumsum(pdf)))\n",
    "\n",
    "    u = np.random.uniform(size=(size))\n",
    "    indices = np.searchsorted(cdf, u)\n",
    "\n",
    "    # define the boundaries\n",
    "    below = np.maximum(0, indices-1)\n",
    "    above = np.minimum(cdf.shape[-1]-1, indices)\n",
    "    indicesG = np.stack([below, above], axis=-1)  # Contains the bounds of indices returned. Print the value to understand\n",
    "\n",
    "    # gather the cdf according to the indices\n",
    "    cdfG = np.take(cdf, indicesG, axis=-1)\n",
    "\n",
    "    # gather the tVals according to the indices\n",
    "    tValsMidG = np.take(bins, indicesG, axis=-1) # Get the upper and lower bound bins values\n",
    "\n",
    "    # getting the CDF range for the each of the bins\n",
    "    denom = cdfG[..., 1] - cdfG[..., 0]\n",
    "    denom = np.where(denom < 1e-5, np.ones_like(denom), denom)\n",
    "\n",
    "    # Scaling the size to CDF lower and upper bound range (t is like a percentage size compared to its boundary)\n",
    "    t = (u - cdfG[..., 0]) / denom\n",
    "\n",
    "    # Scaling the sample size to bin range\n",
    "    samples = (tValsMidG[..., 0] + t * \n",
    "        (tValsMidG[..., 1] - tValsMidG[..., 0]))\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to actually train the NeRF model following steps need to be followed.\n",
    "\n",
    "1. Read the image dataset and generate ray direction and ray origins\n",
    "2. Encode the ray directions and ray origins\n",
    "3. Pass the encoded values to Coarse NeRF\n",
    "4. From the returned weights, get fine samples\n",
    "5. Pass the fine samples to NeRF model\n",
    "6. Calculate loss (both coarse and fine)\n",
    "7. Back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    raw = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_png(raw, channels=3)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([800, 800, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_image('./Data/ship/train/r_0.png')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68acd5d746db9e112a7343296bb3423d1ae6da35b5d50d333630681f8a968c1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
